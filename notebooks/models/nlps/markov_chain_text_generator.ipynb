{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸ“œ The History and Concept of Markov Chains**\n",
    "\n",
    "#### **ðŸ”¹ Introduction to Markov Chains**\n",
    "\n",
    "AÂ **Markov Chain**Â is aÂ **probabilistic model**Â that describes a sequence of events whereÂ **the next state depends only on the current state**,Â **not on the past states**. This is known as theÂ **Markov Property**Â orÂ **memorylessness**.\n",
    "\n",
    "In simple terms:ðŸ”¹Â **\"What happens next depends only on what is happening now.\"**\n",
    "\n",
    "This concept is widely used inÂ **natural language processing (NLP)**,Â **finance**,Â **game theory**,Â **robotics**, andÂ **genetics**, among other fields.\n",
    "\n",
    "**ðŸ”¹ A Brief History of Markov Chains**\n",
    "---------------------------------------\n",
    "\n",
    "The foundation ofÂ **Markov Chains**Â was laid by the Russian mathematicianÂ **Andrey Markov (1856â€“1922)**Â inÂ **1906**. Markov was interested in understandingÂ **sequences of dependent random events**, particularly in analyzing howÂ **certain letter sequences**Â occur in Russian poetry.\n",
    "\n",
    "Before Markovâ€™s work,Â **probability theory**Â mainly focused on independent eventsâ€”like dice rolls or coin flips. Markov challenged this idea by studyingÂ **dependent**Â events, where the outcome of the next event is influenced by the current state.\n",
    "\n",
    "### **ðŸ“Œ Key Historical Milestones**\n",
    "\n",
    "ðŸ”¹Â **1906**Â â€“ Andrey Markov introduces the concept ofÂ **Markov Processes**Â to study sequences of dependent events.ðŸ”¹Â **1913**Â â€“ Markov applies his theory to analyze letter sequences inÂ **Pushkinâ€™s poetry**, proving that letter occurrences areÂ **not independent**Â but follow a statistical pattern.ðŸ”¹Â **1920s-1950s**Â â€“ Markov Chains gain traction inÂ **statistical physics**Â andÂ **queuing theory**.ðŸ”¹Â **1950s-1970s**Â â€“ Claude Shannon applies Markov Chains toÂ **natural language processing**, laying the groundwork forÂ **text prediction and AI-driven language models**.ðŸ”¹Â **Today**Â â€“ Markov Chains are used inÂ **speech recognition**,Â **AI-powered text generation**,Â **financial modeling**, and evenÂ **predicting web user behavior**Â (Googleâ€™s PageRank algorithm is based on a Markov process).\n",
    "\n",
    "**ðŸ”¹ Understanding Markov Chains in Simple Terms**\n",
    "--------------------------------------------------\n",
    "\n",
    "AÂ **Markov Chain**Â consists of:\n",
    "\n",
    "1.  **States**Â â€“ Possible situations the system can be in.\n",
    "    \n",
    "2.  **Transitions**Â â€“ Movement from one state to another.\n",
    "    \n",
    "3.  **Transition Probabilities**Â â€“ The likelihood of moving from one state to another.\n",
    "    \n",
    "4.  **Initial State**Â â€“ Where the system starts.\n",
    "    \n",
    "\n",
    "Imagine you areÂ **predicting the weather**:\n",
    "\n",
    "*   **States:**Â {Sunny, Rainy, Cloudy}\n",
    "    \n",
    "*   **Transition Probabilities:**\n",
    "    \n",
    "    *   IfÂ **today is Sunny**, thereâ€™s aÂ **70% chance it will stay Sunny**,Â **20% chance of becoming Cloudy**, andÂ **10% chance of Rain**.\n",
    "        \n",
    "    *   IfÂ **today is Rainy**, thereâ€™s aÂ **60% chance it will keep raining**,Â **30% chance it will become Cloudy**, andÂ **10% chance of becoming Sunny**.\n",
    "        \n",
    "\n",
    "This forms aÂ **probabilistic model**Â that can predict future weather patterns based onÂ **only the current dayâ€™s weather**.\n",
    "\n",
    "**ðŸ”¹ Types of Markov Chains**\n",
    "-----------------------------\n",
    "\n",
    "1.  **Discrete-Time Markov Chains (DTMC)**Â â€“ The system moves from one state to another atÂ **fixed time steps**Â (e.g., predicting weather each day).\n",
    "    \n",
    "2.  **Continuous-Time Markov Chains (CTMC)**Â â€“ The system transitionsÂ **continuously over time**, like modelingÂ **chemical reactions**Â orÂ **customer arrivals at a store**.\n",
    "    \n",
    "3.  **Hidden Markov Models (HMMs)**Â â€“ Used when states areÂ **not directly observable**Â but can be inferred (e.g.,Â **speech recognition**,Â **part-of-speech tagging**Â in NLP).\n",
    "    \n",
    "\n",
    "**ðŸ”¹ Why Are Markov Chains Important?**\n",
    "---------------------------------------\n",
    "\n",
    "âœ”Â **Used in AI and NLP**Â â€“ Markov Chains powerÂ **spell checkers, text predictors, and chatbot responses**.âœ”Â **Search Engines (Googleâ€™s PageRank)**Â â€“ Google's ranking algorithm is based on aÂ **Markov Process**Â to determine the importance of web pages.âœ”Â **Finance & Stock Market Modeling**Â â€“ Used toÂ **predict stock trends**Â andÂ **market behavior**.âœ”Â **Speech Recognition**Â â€“ Virtual assistants likeÂ **Siri and Google Assistant**Â rely onÂ **Hidden Markov Models**Â (HMMs).âœ”Â **Biology & Genetics**Â â€“ Used to modelÂ **DNA sequences and genetic mutations**.\n",
    "\n",
    "**ðŸ”¹ Real-World Example: Markov Chains in Text Prediction**\n",
    "-----------------------------------------------------------\n",
    "\n",
    "Consider an AI-poweredÂ **autocomplete system**Â that predicts the next word in a sentence.\n",
    "\n",
    "### **Example**:\n",
    "\n",
    "If your sentence starts with:ðŸ‘‰Â **\"I am going to the\"**,the model might predict:\n",
    "\n",
    "*   \"store\" withÂ **40% probability**\n",
    "    \n",
    "*   \"park\" withÂ **30% probability**\n",
    "    \n",
    "*   \"gym\" withÂ **20% probability**\n",
    "    \n",
    "*   \"beach\" withÂ **10% probability**\n",
    "    \n",
    "\n",
    "The prediction dependsÂ **only on the last few words**, not the entire history of the conversation.\n",
    "\n",
    "**ðŸ”¹ Summary**\n",
    "--------------\n",
    "\n",
    "âœ…Â **Markov Chains**Â model sequences where theÂ **future state depends only on the present state**.âœ… Developed byÂ **Andrey Markov in 1906**Â to analyzeÂ **dependent random events**.âœ… Applied inÂ **AI, NLP, finance, search engines, and biology**.âœ… Used inÂ **text prediction**,Â **weather forecasting**, andÂ **speech recognition**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat soon to finding the premise immediately when it If the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "MarkovChain Text Generator\n",
    "\n",
    "This script implements a Markov Chain-based text generator. It allows training on a given text corpus\n",
    "from CSV files and generating new text sequences based on the learned Markov Chain model.\n",
    "\n",
    "Classes:\n",
    "    - MarkovChain: Represents the Markov Chain model for text generation.\n",
    "\n",
    "Methods:\n",
    "    - __init__: Initializes the Markov Chain with an empty graph.\n",
    "    - _tokenize: Tokenizes input text by removing punctuation, numbers, and splitting into words.\n",
    "    - _train: Trains the Markov Chain by building a graph of word transitions from the input text.\n",
    "    - _read_pd_csv: Reads a CSV file and converts the first column into a single string.\n",
    "    - _generate: Generates a sequence of text based on the trained Markov Chain and a given prompt.\n",
    "    - _train_model: Trains the Markov Chain model using text data from multiple CSV files.\n",
    "\n",
    "Functions:\n",
    "    - predict_next: A standalone function that trains the Markov Chain model and generates text based on user input.\n",
    "\n",
    "Constants:\n",
    "    - CSV_FILE_PATHS: A list of file paths to the CSV files used for training the model.\n",
    "\n",
    "Usage:\n",
    "    1. Create an instance of the `MarkovChain` class.\n",
    "    2. Train the model using the `_train_model` method with the provided CSV files.\n",
    "    3. Generate new text using the `_generate` method with a prompt and desired length.\n",
    "\n",
    "Example:\n",
    "    >>> model = MarkovChain()\n",
    "    >>> trained_model = model._train_model()\n",
    "    >>> prompt = \"This is\"\n",
    "    >>> print(trained_model._generate(prompt, length=10))\n",
    "\n",
    "Dependencies:\n",
    "    - random: Used for randomly selecting the next word during text generation.\n",
    "    - string.punctuation: Used for removing punctuation during tokenization.\n",
    "    - collections.defaultdict: Used for storing the Markov Chain graph as a dictionary of lists.\n",
    "    - pandas: Used for reading and processing CSV files.\n",
    "\n",
    "Notes:\n",
    "    - The `_tokenize` method removes punctuation and numbers, converts newlines to spaces, and splits text into words.\n",
    "    - The `_train` method builds a graph where each word points to a list of possible next words.\n",
    "    - The `_generate` method uses the graph to create a sequence of words, starting from the last word in the prompt.\n",
    "    - The `_train_model` method combines text from multiple CSV files and trains the model.\n",
    "\n",
    "Limitations:\n",
    "    - The model assumes that the input text is well-formed and does not handle edge cases like empty input gracefully.\n",
    "    - The generated text may not always be coherent, as it relies purely on word transitions without considering grammar or context.\n",
    "    - The `_generate` method assumes that the graph has been trained before generating text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# The `random` module is used to randomly select the next word during text generation.\n",
    "# Specifically, the `random.choice` method is used to pick a word from the list of possible next words.\n",
    "import random\n",
    "\n",
    "# The `punctuation` constant from the `string` module provides a list of all punctuation characters.\n",
    "# It is used in the `_tokenize` method to remove punctuation from the input text during tokenization.\n",
    "from string import punctuation\n",
    "\n",
    "# The `defaultdict` class from the `collections` module is used to create the Markov Chain graph.\n",
    "# It initializes the graph as a dictionary where each key (a word) maps to a list of possible next words.\n",
    "# This simplifies the process of appending new words to the graph without needing to check for key existence.import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# The `pandas` library is imported as `pd` to provide data manipulation and analysis tools.\n",
    "# It is used in this script to read CSV files and handle data in a structured format (DataFrame).\n",
    "# Specifically, `pandas.read_csv` is used to load CSV data, and `pandas.DataFrame` is used to create and manipulate tabular data.\n",
    "import pandas as pd\n",
    "\n",
    "class MarkovChain:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the MarkovChain instance.\n",
    "\n",
    "        This constructor sets up the Markov Chain graph as a `defaultdict` of lists. \n",
    "        Each key in the graph represents a word, and the corresponding value is a list \n",
    "        of words that can follow it based on the training data.\n",
    "\n",
    "        Attributes:\n",
    "            graph (defaultdict): A dictionary where each key is a word and the value \n",
    "                                is a list of possible next words.\n",
    "        \"\"\"\n",
    "        self.graph = defaultdict(list)\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        \"\"\"\n",
    "        Tokenizes input text by removing punctuation, numeric characters, and splitting it into words.\n",
    "\n",
    "        This method processes the input text to prepare it for further analysis or training. It removes\n",
    "        all punctuation and numeric characters, leaving only alphabetic characters and spaces. The cleaned\n",
    "        text is then split into individual words (tokens), and any empty strings resulting from the split\n",
    "        operation are filtered out.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text to be tokenized.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of tokens (words) extracted from the input text.\n",
    "\n",
    "        Example:\n",
    "            >>> markov_chain = MarkovChain()\n",
    "            >>> markov_chain._tokenize(\"Hello, world! 123\")\n",
    "            ['Hello', 'world']\n",
    "\n",
    "        Notes:\n",
    "            - Punctuation and numeric characters are removed using a generator expression.\n",
    "            - The `split()` method is used to split the cleaned text into words.\n",
    "            - Empty strings are filtered out using a list comprehension.\n",
    "\n",
    "        Limitations:\n",
    "            - This method assumes that the input text is a single string.\n",
    "            - It does not handle special cases like non-ASCII characters or text with mixed encodings.\n",
    "        \"\"\"\n",
    "        # Remove punctuation and numeric characters\n",
    "        text = ''.join(char for char in text if char.isalpha() or char.isspace())\n",
    "        # Split into words and filter out empty strings\n",
    "        tokens = [word for word in text.split() if word]\n",
    "        return tokens\n",
    "    \n",
    "    def _train(self, text):\n",
    "        \"\"\"\n",
    "        Trains the Markov Chain model by building a graph of word transitions from the input text.\n",
    "\n",
    "        This method processes the input text to construct a graph where each word points to a list of possible\n",
    "        next words based on the input text. The graph is stored as a `defaultdict` of lists.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text used to train the Markov Chain model.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Example:\n",
    "            >>> markov_chain = MarkovChain()\n",
    "            >>> markov_chain._train(\"Hello world. Hello again.\")\n",
    "            >>> print(markov_chain.graph)\n",
    "            {'Hello': ['world', 'again'], 'world': ['Hello']}\n",
    "\n",
    "        Notes:\n",
    "            - The input text is preprocessed to ensure proper spacing between words and sentences.\n",
    "            - The `_tokenize` method is used to split the text into tokens (words).\n",
    "            - For each pair of consecutive tokens, the first token is added as a key in the graph, and the second\n",
    "            token is appended to the list of possible next words for that key.\n",
    "\n",
    "        Limitations:\n",
    "            - This method assumes that the input text is well-formed and does not handle edge cases like empty input.\n",
    "            - If the input text contains only one word, the graph will have that word as a key with an empty list as its value.\n",
    "        \"\"\"\n",
    "        # Ensure proper spacing between words and sentences\n",
    "        text = text.replace(\".\", \". \").replace(\",\", \", \").strip()\n",
    "        tokens = self._tokenize(text)\n",
    "        for i in range(len(tokens) - 1):\n",
    "            self.graph[tokens[i]].append(tokens[i + 1])\n",
    "    \n",
    "    def _read_pd_csv(self, csv_file_path, header=None):\n",
    "        \"\"\"\n",
    "        Reads a CSV file into a pandas DataFrame and converts the first column to a single string.\n",
    "\n",
    "        This method reads the specified CSV file, extracts the first column, and concatenates its rows\n",
    "        into a single string, with each row separated by a newline character.\n",
    "\n",
    "        Args:\n",
    "            csv_file_path (str): The path to the CSV file.\n",
    "            header (int or None): Row number to use as the column names, or None if the CSV files have no headers.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing all rows of the first column, separated by newlines.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If there is an error reading or processing the CSV file.\n",
    "\n",
    "        Example:\n",
    "            >>> markov_chain = MarkovChain()\n",
    "            >>> text = markov_chain._read_pd_csv(\"example.csv\")\n",
    "            >>> print(text)\n",
    "            \"Hello world\\nThis is a test\"\n",
    "\n",
    "        Notes:\n",
    "            - The method uses `pandas.read_csv` to load the CSV file into a DataFrame.\n",
    "            - The first column of the DataFrame is converted to a string, with rows joined by newline characters.\n",
    "            - If the CSV file is empty or does not contain a valid first column, the method will return an empty string.\n",
    "\n",
    "        Limitations:\n",
    "            - The method assumes that the CSV file is well-formed and encoded in UTF-8.\n",
    "            - If the CSV file contains multiple columns, only the first column is processed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(csv_file_path, encoding='UTF-8', header=header)\n",
    "            \n",
    "            # Convert the first column to a string with rows separated by \"\\n\"\n",
    "            # First column is the comment, the second being sentiment\n",
    "            first_column_as_string = \"\\n\".join(df.iloc[:, 0].astype(str))\n",
    "            return first_column_as_string\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing CSV file at {csv_file_path}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    # Define constants for CSV file paths\n",
    "    CSV_FILE_PATHS = [\n",
    "        \"../../../csv_datasets/markov_chain_impression_dataset.csv\",\n",
    "        \"../../../csv_datasets/reddit_social_media_comments.csv\",\n",
    "        \"../../../csv_datasets/twitter_social_media_comments.csv\",\n",
    "        \"../../../csv_datasets/imdb_movie_reviews.csv\",\n",
    "        \"../../../csv_datasets/dcat_train_data.csv\",\n",
    "    ]\n",
    "               \n",
    "    def _generate(self, prompt, length=10):\n",
    "        \"\"\"\n",
    "        Generates a sequence of text based on the trained Markov Chain and a given prompt.\n",
    "\n",
    "        This method uses the Markov Chain graph to generate a sequence of words. It starts with the \n",
    "        last word in the given prompt and iteratively selects the next word based on the possible \n",
    "        transitions in the graph. The process continues until the desired sequence length is reached.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The initial text to start the generation. The last word of the prompt is \n",
    "                        used as the starting point for the generation.\n",
    "            length (int): The number of words to generate in the sequence (default is 10).\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the generated sequence of text.\n",
    "\n",
    "        Notes:\n",
    "            - The `_tokenize` method is used to extract the last word from the prompt.\n",
    "            - The `random.choice` method is used to randomly select the next word from the list of \n",
    "            possible transitions for the current word.\n",
    "            - If no transitions are available for the current word, the generation process skips to \n",
    "            the next iteration without adding a new word.\n",
    "        \"\"\"\n",
    "        # Get the last token from the prompt\n",
    "        current = self._tokenize(prompt)[-1]\n",
    "        # Initialize the output with the prompt\n",
    "        output = prompt\n",
    "        for i in range(length):\n",
    "            # Look up the options in the graph dictionary\n",
    "            options = self.graph.get(current, [])\n",
    "            if not options:\n",
    "                continue\n",
    "            # Use random.choice to pick the next word\n",
    "            current = random.choice(options)\n",
    "            # Add the selected word to the output\n",
    "            output += f\" {current}\"\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def _train_model(self, csv_file_paths=CSV_FILE_PATHS, csv_header=None):\n",
    "        \"\"\"\n",
    "        Trains the Markov Chain model using text data from multiple CSV files.\n",
    "\n",
    "        This method reads text data from the specified CSV file paths, processes the first column \n",
    "        of each file into a single string, and trains a Markov Chain model using the combined text.\n",
    "\n",
    "        Args:\n",
    "            csv_file_paths (list of str): A list of file paths to the CSV files containing the training data.\n",
    "            csv_header (int or None): Row number to use as the column names, or None if the CSV files have no headers.\n",
    "\n",
    "        Returns:\n",
    "            MarkovChain: An instance of the MarkovChain class trained on the combined text data.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If no CSV file paths are provided.\n",
    "            Exception: If any error occurs while reading or processing the CSV files.\n",
    "\n",
    "        Notes:\n",
    "            - The `_read_pd_csv` function is used to read and process each CSV file.\n",
    "            - The first column of each CSV file is converted into a string, and all strings are concatenated.\n",
    "            - The concatenated text is used to train the Markov Chain model.\n",
    "        \"\"\"\n",
    "        if not csv_file_paths:\n",
    "            raise ValueError(\"No CSV file paths provided.\")\n",
    "        else:\n",
    "            text = \"\"\n",
    "            for csv_file_path in csv_file_paths:\n",
    "                text += self._read_pd_csv(csv_file_path, header=csv_header)\n",
    "            self._train(text)\n",
    "            return self\n",
    "\n",
    "def predict_next(user_input='A cat'):\n",
    "    \"\"\"\n",
    "    Trains the Markov Chain model and generates text based on user input.\n",
    "    \"\"\"\n",
    "    model = MarkovChain()\n",
    "    trained_model = model._train_model()\n",
    "    if user_input is None:\n",
    "        user_input = input(\"Enter a prompt: \")\n",
    "    print(trained_model._generate(user_input, length=10))\n",
    "\n",
    "# Predict next word based on user input\n",
    "predict_next()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
